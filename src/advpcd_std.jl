"""
    advpcd!(rbm, data; q, Q, ...)

Trains the RBM on data using Persistent Contrastive divergence with constraints.
Matrix `q` contains the 1st-order constraints, that `q[...,t]' * W` be small, for each `t`.
Matrix `Q` contains the 2nd-order constraints, that `W' * Q[...,t] * W` be small, for each `t`.
"""
function advpcd!(
    rbm::StandardizedRBM,
    data::AbstractArray;

    batchsize::Int = 1,
    shuffle::Bool = true,

    iters::Int = 1, # number of parameter updates

    steps::Int = 1, # fantasy chains MC steps
    vm::AbstractArray = sample_from_inputs(rbm.visible, Falses(size(rbm.visible)..., batchsize)),

    moments = moments_from_samples(rbm.visible, data), # sufficient statistics for visible layer

    # regularization
    l2_fields::Real = 0, # visible fields L2 regularization
    l1_weights::Real = 0, # weights L1 regularization
    l2_weights::Real = 0, # weights L2 regularization
    l2l1_weights::Real = 0, # weights L2/L1 regularization

    # "pseudocount" for estimating variances of v and h and damping
    damping::Real = 1//100,
    Ïµv::Real = 0, Ïµh::Real = 0,

    optim::AbstractRule = Adam(),
    ps = (; visible = rbm.visible.par, hidden = rbm.hidden.par, w = rbm.w),
    state = setup(optim, ps),

    # Absorb the scale_h into the hidden unit activation (for continuous hidden units).
    # Results in hidden units with var(h) ~ 1.
    rescale_hidden::Bool = true,

    callback = Returns(nothing),

    # gauge
    zerosum::Bool = true, # zerosum gauge for Potts layers

    # constraints are given as a list, where each entry describes the constraints applied
    # to a group of hidden units (the groups must be exclusive)
    # For Potts units, q, Q should themselves be zerosum!
    qs::AbstractVector{<:AbstractArray{<:Real}} = default_qs(rbm), # 1st-order constraints
    Qs::AbstractVector{<:AbstractArray{<:Real}} = default_Qs(rbm, qs), # 2nd-order constraints
    Î»Q::Real = 0, # 2nd-order adversarial soft constraint, penalty
    # indices of constrained hidden units in each group (the groups must not intersect)
    â„‹s::AbstractVector{<:CartesianIndices} = default_â„‹s(rbm, qs)
)
    @assert size(data) == (size(rbm.visible)..., size(data)[end])
    @assert 0 â‰¤ damping â‰¤ 1

    @assert 0 â‰¤ Î»Q < Inf # hard 2nd-order constraint not supported
    @assert length(qs) == length(Qs) == length(â„‹s)
    @assert empty_intersections(â„‹s)

    standardize_visible_from_data!(rbm, data; Ïµ = Ïµv)

    # indices in visible dimensions
    ð’± = CartesianIndices(size(rbm.visible))

    # gauge constraints
    zerosum && zerosum!(rbm)
    rescale_hidden && rescale_hidden_activations!(rbm)

    # initial centering from data
    if rbm isa CenteredRBM
        center_from_data!(rbm, data)
    end

    # impose hard 1st-order constraint on initial weights
    qs_inv = map(pseudo_inv_of_q, qs)
    for (q, â„‹, qinv) in zip(qs, â„‹s, qs_inv)
        rbm.w[ð’±, â„‹] .= kernelproj(rbm.w[ð’±, â„‹], q; qinv)
    end

    for (iter, (vd,)) in zip(1:iters, infinite_minibatches(data; batchsize, shuffle))
        # update Markov chains
        vm = sample_v_from_v(rbm, vm; steps)

        # update standardization
        standardize_hidden_from_v!(rbm, vd; damping, Ïµ=Ïµh)

        # compute gradient
        âˆ‚d = âˆ‚free_energy(rbm, vd; moments)
        âˆ‚m = âˆ‚free_energy(rbm, vm)
        âˆ‚ = âˆ‚d - âˆ‚m

        # regularize
        âˆ‚regularize!(âˆ‚, rbm; l2_fields, l1_weights, l2_weights, l2l1_weights, zerosum)

        # 2nd order constraint is soft, update gradient accordingly
        if 0 < Î»Q < Inf
            for (Q, â„‹) in zip(Qs, â„‹s)
                âˆ‚.w[ð’±, â„‹] .+= Î»Q .* âˆ‚wQw(rbm.w[ð’±, â„‹], Q)
            end
        end

        # feed gradient to Optimiser rule and update parameters
        gs = (; visible = âˆ‚.visible, hidden = âˆ‚.hidden, w = âˆ‚.w)
        state, ps = update!(state, ps, gs)

        # respect gauge constraints
        rescale_hidden && rescale_hidden_activations!(rbm)
        zerosum && zerosum!(rbm)

        # 1st-order constraint is hard, project weights
        for (q, â„‹, qinv) in zip(qs, â„‹s, qs_inv)
            rbm.w[ð’±, â„‹] .= kernelproj(rbm.w[ð’±, â„‹], q; qinv)
        end

        callback(; rbm, optim, state, ps, iter, vm, vd, âˆ‚)
    end

    return state, ps
end
